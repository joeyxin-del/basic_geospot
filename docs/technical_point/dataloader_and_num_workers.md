# DataLoader å’Œ num_workers æŠ€æœ¯æŒ‡å—

## æ¦‚è¿°

PyTorch çš„ `DataLoader` æ˜¯æ·±åº¦å­¦ä¹ è®­ç»ƒä¸­çš„æ ¸å¿ƒç»„ä»¶ï¼Œè´Ÿè´£é«˜æ•ˆåœ°åŠ è½½å’Œæ‰¹å¤„ç†æ•°æ®ã€‚`num_workers` å‚æ•°æ§åˆ¶æ•°æ®åŠ è½½çš„å¹¶è¡Œç¨‹åº¦ï¼Œå¯¹è®­ç»ƒæ€§èƒ½æœ‰é‡å¤§å½±å“ã€‚æœ¬æ–‡è¯¦ç»†ä»‹ç» DataLoader çš„å·¥ä½œåŸç†ã€num_workers çš„ä½œç”¨æœºåˆ¶ï¼Œä»¥åŠå¸¸è§çš„æ€§èƒ½é—®é¢˜å’Œä¼˜åŒ–ç­–ç•¥ã€‚

## DataLoader åŸºç¡€æ¦‚å¿µ

### ä»€ä¹ˆæ˜¯ DataLoader

DataLoader æ˜¯ PyTorch æä¾›çš„æ•°æ®åŠ è½½å·¥å…·ï¼Œå°†æ•°æ®é›†ï¼ˆDatasetï¼‰è½¬æ¢ä¸ºå¯è¿­ä»£çš„æ‰¹æ¬¡æ•°æ®ã€‚å®ƒè´Ÿè´£ï¼š

- **æ‰¹å¤„ç†**ï¼šå°†å•ä¸ªæ ·æœ¬ç»„åˆæˆæ‰¹æ¬¡
- **æ´—ç‰Œ**ï¼šéšæœºåŒ–æ•°æ®é¡ºåºï¼ˆè®­ç»ƒæ—¶ï¼‰
- **å¹¶è¡ŒåŠ è½½**ï¼šä½¿ç”¨å¤šè¿›ç¨‹åŠ é€Ÿæ•°æ®åŠ è½½
- **å†…å­˜ç®¡ç†**ï¼šä¼˜åŒ– CPU-GPU æ•°æ®ä¼ è¾“

### åŸºæœ¬ç”¨æ³•

```python
from torch.utils.data import DataLoader

# åˆ›å»º DataLoader
train_loader = DataLoader(
    dataset=train_dataset,       # æ•°æ®é›†
    batch_size=32,              # æ‰¹æ¬¡å¤§å°
    shuffle=True,               # æ˜¯å¦æ´—ç‰Œ
    num_workers=4,              # å·¥ä½œè¿›ç¨‹æ•°
    pin_memory=True,            # æ˜¯å¦å›ºå®šå†…å­˜
    persistent_workers=True,    # æ˜¯å¦ä¿æŒå·¥ä½œè¿›ç¨‹å­˜æ´»
    collate_fn=custom_collate   # è‡ªå®šä¹‰æ‰¹å¤„ç†å‡½æ•°
)

# ä½¿ç”¨ DataLoader
for batch_idx, batch in enumerate(train_loader):
    images, labels = batch['image'], batch['label']
    # è®­ç»ƒä»£ç ...
```

## num_workers è¯¦è§£

### å·¥ä½œåŸç†

`num_workers` æ§åˆ¶ç”¨äºæ•°æ®åŠ è½½çš„å­è¿›ç¨‹æ•°é‡ï¼š

- **num_workers=0**ï¼šä¸»è¿›ç¨‹åŠ è½½ï¼Œé˜»å¡å¼
- **num_workers>0**ï¼šå¤šè¿›ç¨‹åŠ è½½ï¼Œå¹¶è¡Œå¤„ç†

### å¤šè¿›ç¨‹æ¶æ„

```
ä¸»è¿›ç¨‹ (è®­ç»ƒå¾ªç¯)
â”œâ”€â”€ GPU è®¡ç®—
â”œâ”€â”€ æ¢¯åº¦æ›´æ–°
â””â”€â”€ æ•°æ®æ¶ˆè´¹

å·¥ä½œè¿›ç¨‹1 â”€â”€ æ•°æ®åŠ è½½
å·¥ä½œè¿›ç¨‹2 â”€â”€ æ•°æ®é¢„å¤„ç†  
å·¥ä½œè¿›ç¨‹3 â”€â”€ å›¾åƒè§£ç 
å·¥ä½œè¿›ç¨‹4 â”€â”€ æ•°æ®å¢å¼º
```

### è¿›ç¨‹ç”Ÿå‘½å‘¨æœŸ

#### ä¼ ç»Ÿæ¨¡å¼ï¼ˆpersistent_workers=Falseï¼‰

```python
# æ¯ä¸ª epoch çš„å¾ªç¯
for epoch in range(epochs):
    for batch in train_loader:  # ğŸ”„ è¿™é‡Œé‡æ–°åˆ›å»ºè¿­ä»£å™¨
        # 1. åˆ›å»ºæ–°çš„ DataLoaderIterator
        # 2. å¯åŠ¨ num_workers ä¸ªå­è¿›ç¨‹
        # 3. åˆ†é…æ•°æ®åŠ è½½ä»»åŠ¡
        # 4. æ”¶é›†æ‰¹æ¬¡æ•°æ®
        # 5. è®­ç»ƒå®Œæˆåé”€æ¯è¿›ç¨‹
        pass
    # epoch ç»“æŸï¼Œæ‰€æœ‰å·¥ä½œè¿›ç¨‹è¢«é”€æ¯
```

#### æŒä¹…åŒ–æ¨¡å¼ï¼ˆpersistent_workers=Trueï¼‰

```python
# å¯åŠ¨æ—¶åˆ›å»ºè¿›ç¨‹ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­ä¿æŒå­˜æ´»
for epoch in range(epochs):
    for batch in train_loader:  # âœ… å¤ç”¨ç°æœ‰å·¥ä½œè¿›ç¨‹
        # 1. å¤ç”¨ç°æœ‰çš„å·¥ä½œè¿›ç¨‹
        # 2. ç›´æ¥åˆ†é…æ–°ä»»åŠ¡
        # 3. æ”¶é›†æ‰¹æ¬¡æ•°æ®
        pass
    # epoch ç»“æŸï¼Œå·¥ä½œè¿›ç¨‹ç»§ç»­å­˜æ´»
```

## æ€§èƒ½å½±å“åˆ†æ

### Epoch é—´åœé¡¿é—®é¢˜

#### é—®é¢˜è¡¨ç°

```
Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [05:23<00:00]
â¸ï¸ åœé¡¿ 10-30 ç§’
Epoch 2: 0%|         | 0/200 [00:00<?, ?batch/s]
```

#### æ ¹æœ¬åŸå› 

1. **è¿›ç¨‹é‡å¯å¼€é”€**
   ```python
   # PyTorch å†…éƒ¨å®ç°ï¼ˆç®€åŒ–ç‰ˆï¼‰
   def __iter__(self):
       if self.num_workers > 0:
           # æ¯æ¬¡è¿­ä»£éƒ½åˆ›å»ºæ–°çš„å¤šè¿›ç¨‹è¿­ä»£å™¨
           return _MultiProcessingDataLoaderIter(self)
   
   class _MultiProcessingDataLoaderIter:
       def __init__(self, loader):
           self._spawn_workers()  # å¯åŠ¨å·¥ä½œè¿›ç¨‹
           
       def _spawn_workers(self):
           for i in range(self.num_workers):
               # åˆ›å»ºå¹¶å¯åŠ¨æ–°è¿›ç¨‹
               w = multiprocessing.Process(target=_worker_loop)
               w.start()
   ```

2. **æ•°æ®æ´—ç‰Œå¼€é”€**
   ```python
   shuffle=True  # æ¯ä¸ª epoch é‡æ–°æ´—ç‰Œæ•´ä¸ªæ•°æ®é›†
   ```

3. **å†…å­˜ç®¡ç†å¼€é”€**
   - è¿›ç¨‹é—´é€šä¿¡é˜Ÿåˆ—é‡å»º
   - å…±äº«å†…å­˜é‡æ–°åˆ†é…
   - ç¼“å­˜æ¸…ç†å’Œé‡å»º

### æ€§èƒ½æµ‹è¯•å¯¹æ¯”

#### åœºæ™¯ï¼š6400 å¼ è®­ç»ƒå›¾åƒï¼Œæ‰¹æ¬¡å¤§å° 32

| num_workers | epoch é—´åœé¡¿ | å• batch è€—æ—¶ | æ€»ä½“æ€§èƒ½ |
|-------------|--------------|---------------|----------|
| 0           | 0s           | 2.1s          | æ…¢       |
| 2           | 3-5s         | 0.8s          | è‰¯å¥½     |
| 4           | 8-12s        | 0.6s          | ä¸€èˆ¬     |
| 8           | 15-25s       | 0.5s          | å·®       |

#### ç»“è®º

- **åœé¡¿æ—¶é—´** âˆ num_workers æ•°é‡
- **å•æ‰¹æ¬¡é€Ÿåº¦** âˆ 1/num_workersï¼ˆæœ‰ä¸Šé™ï¼‰
- **æœ€ä¼˜å¹³è¡¡ç‚¹**ï¼šé€šå¸¸åœ¨ 2-4 ä¸ªå·¥ä½œè¿›ç¨‹

## ä¼˜åŒ–ç­–ç•¥

### 1. å¯ç”¨æŒä¹…åŒ–å·¥ä½œè¿›ç¨‹

```python
train_loader = DataLoader(
    dataset,
    batch_size=32,
    num_workers=4,
    persistent_workers=True if num_workers > 0 else False,  # ğŸ”‘ å…³é”®ä¼˜åŒ–
    pin_memory=True
)
```

**æ•ˆæœ**ï¼šå‡å°‘ 80-90% çš„ epoch é—´åœé¡¿æ—¶é—´

### 2. åˆç†è®¾ç½®å·¥ä½œè¿›ç¨‹æ•°

```python
import os

# æ–¹æ¡ˆ 1ï¼šåŸºäº CPU æ ¸å¿ƒæ•°
num_workers = min(4, os.cpu_count())

# æ–¹æ¡ˆ 2ï¼šåŸºäº GPU æ•°é‡
num_workers = min(4, torch.cuda.device_count() * 2)

# æ–¹æ¡ˆ 3ï¼šåŠ¨æ€è°ƒæ•´
if batch_size <= 8:
    num_workers = 2
elif batch_size <= 32:
    num_workers = 4
else:
    num_workers = min(8, os.cpu_count())
```

### 3. å†…å­˜ä¼˜åŒ–

```python
train_loader = DataLoader(
    dataset,
    batch_size=32,
    num_workers=4,
    pin_memory=True,                    # GPU è®­ç»ƒæ—¶å¯ç”¨
    persistent_workers=True,
    prefetch_factor=2,                  # é¢„å–æ‰¹æ¬¡æ•°é‡
    multiprocessing_context='spawn'     # Windows ä¸‹æ¨è
)
```

### 4. è‡ªå®šä¹‰ collate å‡½æ•°ä¼˜åŒ–

```python
def optimized_collate_fn(batch):
    """ä¼˜åŒ–çš„æ‰¹å¤„ç†å‡½æ•°"""
    # é¿å…åœ¨å·¥ä½œè¿›ç¨‹ä¸­è¿›è¡Œé‡å¤è½¬æ¢
    images = torch.stack([item['image'] for item in batch])
    labels = [item['label'] for item in batch]
    
    return {
        'image': images,
        'label': labels
    }
```

## å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### é—®é¢˜ 1ï¼šå·¥ä½œè¿›ç¨‹å¡æ­»

**ç°è±¡**ï¼šè®­ç»ƒå¡åœ¨æ•°æ®åŠ è½½é˜¶æ®µ

**åŸå› **ï¼š
- å·¥ä½œè¿›ç¨‹å†…å­˜ä¸è¶³
- æ•°æ®é›†è®¿é—®å†²çª
- æ­»é”

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# å‡å°‘å·¥ä½œè¿›ç¨‹æ•°
num_workers = 1

# æˆ–ä½¿ç”¨ä¸»è¿›ç¨‹åŠ è½½
num_workers = 0

# æ£€æŸ¥æ•°æ®é›†å®ç°
def __getitem__(self, idx):
    # ç¡®ä¿çº¿ç¨‹å®‰å…¨
    with self.lock:
        return self.load_data(idx)
```

### é—®é¢˜ 2ï¼šå†…å­˜ä½¿ç”¨è¿‡é«˜

**ç°è±¡**ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­å†…å­˜æŒç»­å¢é•¿

**åŸå› **ï¼š
- å·¥ä½œè¿›ç¨‹å†…å­˜æ³„æ¼
- æ‰¹æ¬¡æ•°æ®ç§¯ç´¯

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# å¯ç”¨å†…å­˜æ¸…ç†
torch.multiprocessing.set_sharing_strategy('file_system')

# å‡å°‘é¢„å–
prefetch_factor=1

# å®šæœŸæ¸…ç†
if batch_idx % 100 == 0:
    gc.collect()
```

### é—®é¢˜ 3ï¼šWindows å…¼å®¹æ€§é—®é¢˜

**ç°è±¡**ï¼šå¤šè¿›ç¨‹å¯åŠ¨å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
import multiprocessing as mp

# è®¾ç½®å¯åŠ¨æ–¹æ³•
if __name__ == '__main__':
    mp.set_start_method('spawn', force=True)
    
# æˆ–åœ¨ DataLoader ä¸­è®¾ç½®
train_loader = DataLoader(
    dataset,
    num_workers=4,
    multiprocessing_context=mp.get_context('spawn')
)
```

## æ€§èƒ½è°ƒä¼˜å»ºè®®

### 1. æ¸è¿›å¼è°ƒä¼˜

```python
# æ­¥éª¤ 1ï¼šç¡®å®šåŸºçº¿ï¼ˆä¸»è¿›ç¨‹ï¼‰
num_workers = 0

# æ­¥éª¤ 2ï¼šå°è¯•å°‘é‡å·¥ä½œè¿›ç¨‹
num_workers = 2

# æ­¥éª¤ 3ï¼šé€æ­¥å¢åŠ å¹¶æµ‹è¯•
num_workers = 4

# æ­¥éª¤ 4ï¼šæ‰¾åˆ°æœ€ä¼˜ç‚¹
optimal_workers = find_optimal_workers()
```

### 2. ç›‘æ§æŒ‡æ ‡

```python
import time

# ç›‘æ§æ‰¹æ¬¡åŠ è½½æ—¶é—´
start_time = time.time()
for batch_idx, batch in enumerate(train_loader):
    load_time = time.time() - start_time
    
    # è®­ç»ƒä»£ç 
    train_start = time.time()
    # ... è®­ç»ƒé€»è¾‘ ...
    train_time = time.time() - train_start
    
    # æ€§èƒ½åˆ†æ
    if batch_idx % 10 == 0:
        print(f"Batch {batch_idx}: Load={load_time:.3f}s, Train={train_time:.3f}s")
    
    start_time = time.time()
```

### 3. é…ç½®æ¨¡æ¿

#### å°æ•°æ®é›†é…ç½®ï¼ˆ< 1000 æ ·æœ¬ï¼‰
```yaml
training:
  batch_size: 16
  num_workers: 1
  persistent_workers: false
```

#### ä¸­ç­‰æ•°æ®é›†é…ç½®ï¼ˆ1K-10K æ ·æœ¬ï¼‰
```yaml
training:
  batch_size: 32
  num_workers: 2
  persistent_workers: true
```

#### å¤§æ•°æ®é›†é…ç½®ï¼ˆ> 10K æ ·æœ¬ï¼‰
```yaml
training:
  batch_size: 32
  num_workers: 4
  persistent_workers: true
  pin_memory: true
  prefetch_factor: 2
```

## å®é™…æ¡ˆä¾‹ï¼šSpotGEO é¡¹ç›®ä¼˜åŒ–

### ä¼˜åŒ–å‰

```python
train_loader = DataLoader(
    train_dataset,
    batch_size=32,
    shuffle=True,
    num_workers=8,                   # âŒ è¿‡å¤šå·¥ä½œè¿›ç¨‹
    pin_memory=True,
    # persistent_workers=False      # âŒ é»˜è®¤ä¸æŒä¹…åŒ–
)
```

**é—®é¢˜**ï¼šæ¯ä¸ª epoch é—´åœé¡¿ 15-25 ç§’

### ä¼˜åŒ–å

```python
train_loader = DataLoader(
    train_dataset,
    batch_size=32,
    shuffle=True,
    num_workers=2,                   # âœ… åˆç†çš„å·¥ä½œè¿›ç¨‹æ•°
    pin_memory=True,
    persistent_workers=True,         # âœ… å¯ç”¨æŒä¹…åŒ–
    collate_fn=custom_collate_fn
)
```

**æ•ˆæœ**ï¼šepoch é—´åœé¡¿å‡å°‘åˆ° 2-3 ç§’

## æ€»ç»“

1. **num_workers** ä¸æ˜¯è¶Šå¤šè¶Šå¥½ï¼Œéœ€è¦æ‰¾åˆ°å¹³è¡¡ç‚¹
2. **persistent_workers=True** æ˜¯å‡å°‘ epoch é—´åœé¡¿çš„å…³é”®
3. **ç›‘æ§å’Œæµ‹è¯•** æ˜¯æ‰¾åˆ°æœ€ä¼˜é…ç½®çš„å”¯ä¸€æ–¹æ³•
4. **æ•°æ®é›†ç‰¹æ€§** å½±å“æœ€ä¼˜ num_workers é€‰æ‹©
5. **ç¡¬ä»¶ç¯å¢ƒ** å†³å®šæ€§èƒ½ä¸Šé™

æ­£ç¡®é…ç½® DataLoader å¯ä»¥æ˜¾è‘—æå‡è®­ç»ƒæ•ˆç‡ï¼Œå‡å°‘ä¸å¿…è¦çš„ç­‰å¾…æ—¶é—´ã€‚ 